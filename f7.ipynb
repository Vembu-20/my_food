{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNktWSrjGvnr/q1wX7eHCM8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ARTKvKE44Fcx"},"outputs":[],"source":["'''\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.datasets import mnist\n","from keras.models import Model\n","from keras.layers import Input, Dense\n","from keras.optimizers import Adam\n","from sklearn.manifold import TSNE\n","\n","# 1. Load and Preprocess the MNIST Data\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Normalize pixel values to be between 0 and 1\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","# Flatten the 28x28 images into vectors of 784 elements\n","x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n","x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n","\n","# 2. Build the Autoencoder Model\n","# This is the size of our encoded representations\n","encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n","\n","# This is our input placeholder\n","input_img = Input(shape=(784,))\n","\n","# \"encoded\" is the encoded representation of the input\n","encoded = Dense(encoding_dim, activation='relu')(input_img)\n","\n","# \"decoded\" is the lossy reconstruction of the input\n","# CORRECTED THIS LINE: The input to this layer should be 'encoded'\n","decoded = Dense(784, activation='sigmoid')(encoded)\n","\n","# This model maps an input to its reconstruction\n","autoencoder = Model(input_img, decoded)\n","\n","# This model maps an input to its encoded representation\n","encoder = Model(input_img, encoded)\n","\n","# Create a placeholder for an encoded (32-dimensional) input\n","encoded_input = Input(shape=(encoding_dim,))\n","# Retrieve the last layer of the autoencoder model\n","decoder_layer = autoencoder.layers[-1]\n","# Create the decoder model\n","decoder = Model(encoded_input, decoder_layer(encoded_input))\n","\n","# Compile the autoencoder\n","autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","# 3. Train the Autoencoder\n","history = autoencoder.fit(x_train, x_train,\n","                epochs=50,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(x_test, x_test))\n","\n","# 4. Predict on the test data to get the reconstructed images\n","decoded_imgs = autoencoder.predict(x_test)\n","\n","# 5. Visualize the Original and Reconstructed Images\n","n = 10  # How many digits we will display\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    # Display original\n","    ax = plt.subplot(2, n, i + 1)\n","    plt.imshow(x_test[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    if i == 0:\n","        ax.set_title(\"Original Images\", loc='left')\n","\n","\n","    # Display reconstruction\n","    ax = plt.subplot(2, n, i + 1 + n)\n","    plt.imshow(decoded_imgs[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    if i == 0:\n","        ax.set_title(\"Reconstructed Images\", loc='left')\n","plt.show()\n","\n","# 6. Plotting the Training and Validation Loss\n","plt.figure(figsize=(10, 5))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Model Loss During Training')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# 7. Visualize the Latent Space using t-SNE\n","# Use the encoder to get the latent representations of the test data\n","encoded_imgs = encoder.predict(x_test)\n","\n","# Use t-SNE to reduce the dimensionality of the latent space to 2D\n","tsne = TSNE(n_components=2, random_state=42)\n","encoded_imgs_2d = tsne.fit_transform(encoded_imgs)\n","\n","# Plot the 2D latent space\n","plt.figure(figsize=(12, 10))\n","plt.scatter(encoded_imgs_2d[:, 0], encoded_imgs_2d[:, 1], c=y_test, cmap='jet', s=10)\n","plt.colorbar()\n","plt.title('t-SNE visualization of the MNIST latent space')\n","plt.xlabel('t-SNE dimension 1')\n","plt.ylabel('t-SNE dimension 2')\n","plt.show()'''"]}]}